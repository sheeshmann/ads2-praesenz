{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - tensorflow.keras Intro mit Baumdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 21:30:54.174953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformierte Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repml.fast import get_transformed_tree_data\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_transformed_tree_data(components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220307, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell mit der Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(\n",
    "            input_shape=[\n",
    "                x_train.shape[1],\n",
    "            ]\n",
    "        ),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7651 (29.89 KB)\n",
      "Trainable params: 7651 (29.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging mit TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "tb_callback = TensorBoard(\"./tf_logs/tree-nn/trial-A\", update_freq=1)\n",
    "es_callback = EarlyStopping(monitor=\"loss\", patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "3443/3443 - 40s - loss: 403044.3750 - mae: 305.6706 - val_loss: 1951.5757 - val_mae: 31.7882 - 40s/epoch - 12ms/step\n",
      "Epoch 2/350\n",
      "3443/3443 - 35s - loss: 935.7590 - mae: 21.1920 - val_loss: 475.7950 - val_mae: 15.3573 - 35s/epoch - 10ms/step\n",
      "Epoch 3/350\n",
      "3443/3443 - 34s - loss: 374.6759 - mae: 13.6794 - val_loss: 322.3090 - val_mae: 12.5960 - 34s/epoch - 10ms/step\n",
      "Epoch 4/350\n",
      "3443/3443 - 51s - loss: 293.3372 - mae: 12.1369 - val_loss: 283.7797 - val_mae: 11.7386 - 51s/epoch - 15ms/step\n",
      "Epoch 5/350\n",
      "3443/3443 - 36s - loss: 265.0407 - mae: 11.4955 - val_loss: 276.5505 - val_mae: 11.8432 - 36s/epoch - 10ms/step\n",
      "Epoch 6/350\n",
      "3443/3443 - 49s - loss: 250.1312 - mae: 11.1495 - val_loss: 257.0118 - val_mae: 11.2612 - 49s/epoch - 14ms/step\n",
      "Epoch 7/350\n",
      "3443/3443 - 31s - loss: 241.7390 - mae: 10.9475 - val_loss: 243.8409 - val_mae: 10.8020 - 31s/epoch - 9ms/step\n",
      "Epoch 8/350\n",
      "3443/3443 - 38s - loss: 235.1051 - mae: 10.7713 - val_loss: 246.4159 - val_mae: 10.9744 - 38s/epoch - 11ms/step\n",
      "Epoch 9/350\n",
      "3443/3443 - 15s - loss: 229.8738 - mae: 10.6322 - val_loss: 234.5298 - val_mae: 10.5656 - 15s/epoch - 4ms/step\n",
      "Epoch 10/350\n",
      "3443/3443 - 25s - loss: 225.4797 - mae: 10.5290 - val_loss: 229.1023 - val_mae: 10.4974 - 25s/epoch - 7ms/step\n",
      "Epoch 11/350\n",
      "3443/3443 - 29s - loss: 222.3757 - mae: 10.4416 - val_loss: 240.1358 - val_mae: 10.8978 - 29s/epoch - 8ms/step\n",
      "Epoch 12/350\n",
      "3443/3443 - 11s - loss: 220.4099 - mae: 10.4134 - val_loss: 238.9841 - val_mae: 10.9344 - 11s/epoch - 3ms/step\n",
      "Epoch 13/350\n",
      "3443/3443 - 27s - loss: 218.2307 - mae: 10.3199 - val_loss: 220.1450 - val_mae: 10.1944 - 27s/epoch - 8ms/step\n",
      "Epoch 14/350\n",
      "3443/3443 - 26s - loss: 215.3062 - mae: 10.2416 - val_loss: 230.2851 - val_mae: 10.6182 - 26s/epoch - 7ms/step\n",
      "Epoch 15/350\n",
      "3443/3443 - 11s - loss: 214.4475 - mae: 10.2185 - val_loss: 217.7079 - val_mae: 10.0754 - 11s/epoch - 3ms/step\n",
      "Epoch 16/350\n",
      "3443/3443 - 14s - loss: 212.4718 - mae: 10.1716 - val_loss: 228.6160 - val_mae: 10.3806 - 14s/epoch - 4ms/step\n",
      "Epoch 17/350\n",
      "3443/3443 - 7s - loss: 211.4979 - mae: 10.1502 - val_loss: 224.8950 - val_mae: 10.4467 - 7s/epoch - 2ms/step\n",
      "Epoch 18/350\n",
      "3443/3443 - 8s - loss: 208.8228 - mae: 10.0722 - val_loss: 231.7466 - val_mae: 10.6782 - 8s/epoch - 2ms/step\n",
      "Epoch 19/350\n",
      "3443/3443 - 8s - loss: 208.0070 - mae: 10.0485 - val_loss: 208.1507 - val_mae: 9.7905 - 8s/epoch - 2ms/step\n",
      "Epoch 20/350\n",
      "3443/3443 - 8s - loss: 207.1481 - mae: 10.0217 - val_loss: 228.1010 - val_mae: 10.3549 - 8s/epoch - 2ms/step\n",
      "Epoch 21/350\n",
      "3443/3443 - 12s - loss: 206.7182 - mae: 10.0049 - val_loss: 227.3078 - val_mae: 10.6025 - 12s/epoch - 3ms/step\n",
      "Epoch 22/350\n",
      "3443/3443 - 10s - loss: 204.9514 - mae: 9.9663 - val_loss: 223.7226 - val_mae: 10.4051 - 10s/epoch - 3ms/step\n",
      "Epoch 23/350\n",
      "3443/3443 - 5s - loss: 203.7234 - mae: 9.9271 - val_loss: 209.3477 - val_mae: 9.8577 - 5s/epoch - 1ms/step\n",
      "Epoch 24/350\n",
      "3443/3443 - 4s - loss: 203.8029 - mae: 9.9386 - val_loss: 220.2797 - val_mae: 10.2667 - 4s/epoch - 1ms/step\n",
      "Epoch 25/350\n",
      "3443/3443 - 4s - loss: 203.4807 - mae: 9.9206 - val_loss: 210.2535 - val_mae: 10.0216 - 4s/epoch - 1ms/step\n",
      "Epoch 26/350\n",
      "3443/3443 - 4s - loss: 202.7531 - mae: 9.8977 - val_loss: 222.0646 - val_mae: 10.4064 - 4s/epoch - 1ms/step\n",
      "Epoch 27/350\n",
      "3443/3443 - 3s - loss: 202.5871 - mae: 9.9011 - val_loss: 208.8832 - val_mae: 9.8425 - 3s/epoch - 1000us/step\n",
      "Epoch 28/350\n",
      "3443/3443 - 3s - loss: 202.0002 - mae: 9.8720 - val_loss: 203.7995 - val_mae: 9.5866 - 3s/epoch - 1ms/step\n",
      "Epoch 29/350\n",
      "3443/3443 - 3s - loss: 200.9494 - mae: 9.8412 - val_loss: 210.0196 - val_mae: 9.8267 - 3s/epoch - 1ms/step\n",
      "Epoch 30/350\n",
      "3443/3443 - 3s - loss: 199.8957 - mae: 9.8241 - val_loss: 209.9034 - val_mae: 9.9596 - 3s/epoch - 1ms/step\n",
      "Epoch 31/350\n",
      "3443/3443 - 3s - loss: 200.4695 - mae: 9.8352 - val_loss: 214.0644 - val_mae: 9.9631 - 3s/epoch - 1ms/step\n",
      "Epoch 32/350\n",
      "3443/3443 - 4s - loss: 199.8678 - mae: 9.8205 - val_loss: 210.7714 - val_mae: 10.0361 - 4s/epoch - 1ms/step\n",
      "Epoch 33/350\n",
      "3443/3443 - 3s - loss: 199.1780 - mae: 9.7941 - val_loss: 215.1724 - val_mae: 10.2115 - 3s/epoch - 986us/step\n",
      "Epoch 34/350\n",
      "3443/3443 - 3s - loss: 198.8241 - mae: 9.7917 - val_loss: 204.1363 - val_mae: 9.7112 - 3s/epoch - 1ms/step\n",
      "Epoch 35/350\n",
      "3443/3443 - 3s - loss: 198.3431 - mae: 9.7618 - val_loss: 208.0808 - val_mae: 9.8752 - 3s/epoch - 992us/step\n",
      "Epoch 36/350\n",
      "3443/3443 - 3s - loss: 197.4220 - mae: 9.7537 - val_loss: 214.7887 - val_mae: 9.9028 - 3s/epoch - 989us/step\n",
      "Epoch 37/350\n",
      "3443/3443 - 3s - loss: 196.5504 - mae: 9.7277 - val_loss: 204.3716 - val_mae: 9.6837 - 3s/epoch - 1ms/step\n",
      "Epoch 38/350\n",
      "3443/3443 - 3s - loss: 197.4736 - mae: 9.7555 - val_loss: 205.6647 - val_mae: 9.8273 - 3s/epoch - 987us/step\n",
      "Epoch 39/350\n",
      "3443/3443 - 3s - loss: 196.6010 - mae: 9.7275 - val_loss: 211.2594 - val_mae: 9.9831 - 3s/epoch - 983us/step\n",
      "Epoch 40/350\n",
      "3443/3443 - 3s - loss: 196.0120 - mae: 9.7156 - val_loss: 202.9850 - val_mae: 9.6994 - 3s/epoch - 995us/step\n",
      "Epoch 41/350\n",
      "3443/3443 - 4s - loss: 195.5538 - mae: 9.6917 - val_loss: 196.6603 - val_mae: 9.4274 - 4s/epoch - 1ms/step\n",
      "Epoch 42/350\n",
      "3443/3443 - 3s - loss: 195.1437 - mae: 9.7052 - val_loss: 210.2090 - val_mae: 9.8755 - 3s/epoch - 981us/step\n",
      "Epoch 43/350\n",
      "3443/3443 - 3s - loss: 194.8917 - mae: 9.6674 - val_loss: 205.4638 - val_mae: 9.7547 - 3s/epoch - 995us/step\n",
      "Epoch 44/350\n",
      "3443/3443 - 3s - loss: 194.3497 - mae: 9.6630 - val_loss: 199.0520 - val_mae: 9.5490 - 3s/epoch - 995us/step\n",
      "Epoch 45/350\n",
      "3443/3443 - 3s - loss: 194.2698 - mae: 9.6626 - val_loss: 203.7908 - val_mae: 9.6893 - 3s/epoch - 978us/step\n",
      "Epoch 46/350\n",
      "3443/3443 - 3s - loss: 193.6829 - mae: 9.6407 - val_loss: 203.1703 - val_mae: 9.7063 - 3s/epoch - 1000us/step\n",
      "Epoch 47/350\n",
      "3443/3443 - 3s - loss: 193.9522 - mae: 9.6514 - val_loss: 218.3445 - val_mae: 10.0808 - 3s/epoch - 1ms/step\n",
      "Epoch 48/350\n",
      "3443/3443 - 4s - loss: 193.6699 - mae: 9.6440 - val_loss: 205.4635 - val_mae: 9.7018 - 4s/epoch - 1ms/step\n",
      "Epoch 49/350\n",
      "3443/3443 - 4s - loss: 193.2597 - mae: 9.6427 - val_loss: 204.6273 - val_mae: 9.7383 - 4s/epoch - 1ms/step\n",
      "Epoch 50/350\n",
      "3443/3443 - 4s - loss: 193.1988 - mae: 9.6238 - val_loss: 200.0448 - val_mae: 9.5555 - 4s/epoch - 1ms/step\n",
      "Epoch 51/350\n",
      "3443/3443 - 4s - loss: 192.9494 - mae: 9.6426 - val_loss: 207.7686 - val_mae: 9.7229 - 4s/epoch - 1ms/step\n",
      "Epoch 52/350\n",
      "3443/3443 - 3s - loss: 192.1024 - mae: 9.5861 - val_loss: 218.2629 - val_mae: 10.3467 - 3s/epoch - 1ms/step\n",
      "Epoch 53/350\n",
      "3443/3443 - 3s - loss: 192.7589 - mae: 9.6096 - val_loss: 215.3093 - val_mae: 10.3131 - 3s/epoch - 1ms/step\n",
      "Epoch 54/350\n",
      "3443/3443 - 4s - loss: 191.7294 - mae: 9.5772 - val_loss: 204.4220 - val_mae: 9.7885 - 4s/epoch - 1ms/step\n",
      "Epoch 55/350\n",
      "3443/3443 - 4s - loss: 191.6564 - mae: 9.5946 - val_loss: 198.8696 - val_mae: 9.4639 - 4s/epoch - 1ms/step\n",
      "Epoch 56/350\n",
      "3443/3443 - 4s - loss: 192.0065 - mae: 9.5874 - val_loss: 201.0196 - val_mae: 9.6295 - 4s/epoch - 1ms/step\n",
      "Epoch 57/350\n",
      "3443/3443 - 4s - loss: 191.1494 - mae: 9.5639 - val_loss: 203.3672 - val_mae: 9.7318 - 4s/epoch - 1ms/step\n",
      "Epoch 58/350\n",
      "3443/3443 - 4s - loss: 191.4848 - mae: 9.5868 - val_loss: 210.3117 - val_mae: 9.9825 - 4s/epoch - 1ms/step\n",
      "Epoch 59/350\n",
      "3443/3443 - 3s - loss: 190.9596 - mae: 9.5672 - val_loss: 199.8777 - val_mae: 9.5692 - 3s/epoch - 1ms/step\n",
      "Epoch 60/350\n",
      "3443/3443 - 4s - loss: 189.8204 - mae: 9.5292 - val_loss: 209.2789 - val_mae: 10.0202 - 4s/epoch - 1ms/step\n",
      "Epoch 61/350\n",
      "3443/3443 - 4s - loss: 189.5000 - mae: 9.5207 - val_loss: 200.9914 - val_mae: 9.6681 - 4s/epoch - 1ms/step\n",
      "Epoch 62/350\n",
      "3443/3443 - 3s - loss: 190.2900 - mae: 9.5623 - val_loss: 204.8051 - val_mae: 9.7625 - 3s/epoch - 1ms/step\n",
      "Epoch 63/350\n",
      "3443/3443 - 4s - loss: 189.9853 - mae: 9.5280 - val_loss: 196.0340 - val_mae: 9.4223 - 4s/epoch - 1ms/step\n",
      "Epoch 64/350\n",
      "3443/3443 - 4s - loss: 189.8934 - mae: 9.5276 - val_loss: 195.5745 - val_mae: 9.4806 - 4s/epoch - 1ms/step\n",
      "Epoch 65/350\n",
      "3443/3443 - 4s - loss: 188.6549 - mae: 9.5020 - val_loss: 205.5818 - val_mae: 9.7086 - 4s/epoch - 1ms/step\n",
      "Epoch 66/350\n",
      "3443/3443 - 4s - loss: 189.3364 - mae: 9.5276 - val_loss: 203.7568 - val_mae: 9.6977 - 4s/epoch - 1ms/step\n",
      "Epoch 67/350\n",
      "3443/3443 - 4s - loss: 188.8193 - mae: 9.5115 - val_loss: 205.1683 - val_mae: 9.8943 - 4s/epoch - 1ms/step\n",
      "Epoch 68/350\n",
      "3443/3443 - 4s - loss: 188.4021 - mae: 9.4815 - val_loss: 198.9723 - val_mae: 9.4696 - 4s/epoch - 1ms/step\n",
      "Epoch 69/350\n",
      "3443/3443 - 4s - loss: 188.5635 - mae: 9.4872 - val_loss: 218.8204 - val_mae: 10.2146 - 4s/epoch - 1ms/step\n",
      "Epoch 70/350\n",
      "3443/3443 - 4s - loss: 188.1294 - mae: 9.4838 - val_loss: 209.7848 - val_mae: 10.0294 - 4s/epoch - 1ms/step\n",
      "Epoch 71/350\n",
      "3443/3443 - 3s - loss: 188.0961 - mae: 9.4693 - val_loss: 203.5077 - val_mae: 9.6948 - 3s/epoch - 1ms/step\n",
      "Epoch 72/350\n",
      "3443/3443 - 4s - loss: 187.8747 - mae: 9.4635 - val_loss: 197.4764 - val_mae: 9.4986 - 4s/epoch - 1ms/step\n",
      "Epoch 73/350\n",
      "3443/3443 - 3s - loss: 188.5899 - mae: 9.4961 - val_loss: 209.1361 - val_mae: 9.9753 - 3s/epoch - 1ms/step\n",
      "Epoch 74/350\n",
      "3443/3443 - 4s - loss: 187.1475 - mae: 9.4554 - val_loss: 203.0403 - val_mae: 9.7935 - 4s/epoch - 1ms/step\n",
      "Epoch 75/350\n",
      "3443/3443 - 4s - loss: 187.2152 - mae: 9.4456 - val_loss: 222.0686 - val_mae: 10.6930 - 4s/epoch - 1ms/step\n",
      "Epoch 76/350\n",
      "3443/3443 - 3s - loss: 187.7071 - mae: 9.4633 - val_loss: 198.1785 - val_mae: 9.5228 - 3s/epoch - 1ms/step\n",
      "Epoch 77/350\n",
      "3443/3443 - 3s - loss: 187.1862 - mae: 9.4566 - val_loss: 208.2267 - val_mae: 9.9405 - 3s/epoch - 1ms/step\n",
      "Epoch 78/350\n",
      "3443/3443 - 4s - loss: 187.7688 - mae: 9.4676 - val_loss: 190.3425 - val_mae: 9.2189 - 4s/epoch - 1ms/step\n",
      "Epoch 79/350\n",
      "3443/3443 - 4s - loss: 186.5474 - mae: 9.4196 - val_loss: 194.9794 - val_mae: 9.4251 - 4s/epoch - 1ms/step\n",
      "Epoch 80/350\n",
      "3443/3443 - 3s - loss: 186.3878 - mae: 9.4411 - val_loss: 194.0653 - val_mae: 9.3655 - 3s/epoch - 1ms/step\n",
      "Epoch 81/350\n",
      "3443/3443 - 4s - loss: 186.0556 - mae: 9.4211 - val_loss: 212.5587 - val_mae: 10.1545 - 4s/epoch - 1ms/step\n",
      "Epoch 82/350\n",
      "3443/3443 - 4s - loss: 186.4304 - mae: 9.4203 - val_loss: 242.5310 - val_mae: 11.2920 - 4s/epoch - 1ms/step\n",
      "Epoch 83/350\n",
      "3443/3443 - 4s - loss: 185.9045 - mae: 9.4200 - val_loss: 190.6511 - val_mae: 9.2763 - 4s/epoch - 1ms/step\n",
      "Epoch 84/350\n",
      "3443/3443 - 4s - loss: 185.3544 - mae: 9.3996 - val_loss: 193.7835 - val_mae: 9.4239 - 4s/epoch - 1ms/step\n",
      "Epoch 85/350\n",
      "3443/3443 - 4s - loss: 185.4412 - mae: 9.3840 - val_loss: 202.1030 - val_mae: 9.6787 - 4s/epoch - 1ms/step\n",
      "Epoch 86/350\n",
      "3443/3443 - 3s - loss: 185.1372 - mae: 9.3889 - val_loss: 200.0373 - val_mae: 9.6728 - 3s/epoch - 1ms/step\n",
      "Epoch 87/350\n",
      "3443/3443 - 4s - loss: 185.4761 - mae: 9.3961 - val_loss: 211.9698 - val_mae: 10.0757 - 4s/epoch - 1ms/step\n",
      "Epoch 88/350\n",
      "3443/3443 - 4s - loss: 185.3734 - mae: 9.3990 - val_loss: 206.2540 - val_mae: 9.9610 - 4s/epoch - 1ms/step\n",
      "Epoch 89/350\n",
      "3443/3443 - 4s - loss: 185.3389 - mae: 9.3975 - val_loss: 207.8388 - val_mae: 9.8545 - 4s/epoch - 1ms/step\n",
      "Epoch 90/350\n",
      "3443/3443 - 4s - loss: 185.4366 - mae: 9.3920 - val_loss: 199.7738 - val_mae: 9.5541 - 4s/epoch - 1ms/step\n",
      "Epoch 91/350\n",
      "3443/3443 - 4s - loss: 185.2251 - mae: 9.3937 - val_loss: 193.9369 - val_mae: 9.3591 - 4s/epoch - 1ms/step\n",
      "Epoch 92/350\n",
      "3443/3443 - 4s - loss: 184.6621 - mae: 9.3705 - val_loss: 196.4271 - val_mae: 9.4744 - 4s/epoch - 1ms/step\n",
      "Epoch 93/350\n",
      "3443/3443 - 3s - loss: 185.0539 - mae: 9.3800 - val_loss: 205.9833 - val_mae: 9.8946 - 3s/epoch - 1ms/step\n",
      "Epoch 94/350\n",
      "3443/3443 - 4s - loss: 184.7148 - mae: 9.3557 - val_loss: 195.2744 - val_mae: 9.3506 - 4s/epoch - 1ms/step\n",
      "Epoch 95/350\n",
      "3443/3443 - 4s - loss: 184.3160 - mae: 9.3608 - val_loss: 195.1597 - val_mae: 9.4416 - 4s/epoch - 1ms/step\n",
      "Epoch 96/350\n",
      "3443/3443 - 3s - loss: 183.7249 - mae: 9.3563 - val_loss: 202.9404 - val_mae: 9.8714 - 3s/epoch - 1ms/step\n",
      "Epoch 97/350\n",
      "3443/3443 - 4s - loss: 183.8393 - mae: 9.3456 - val_loss: 192.6463 - val_mae: 9.3678 - 4s/epoch - 1ms/step\n",
      "Epoch 98/350\n",
      "3443/3443 - 3s - loss: 184.4835 - mae: 9.3676 - val_loss: 200.1755 - val_mae: 9.6875 - 3s/epoch - 1ms/step\n",
      "Epoch 99/350\n",
      "3443/3443 - 4s - loss: 183.9068 - mae: 9.3525 - val_loss: 193.8895 - val_mae: 9.3808 - 4s/epoch - 1ms/step\n",
      "Epoch 100/350\n",
      "3443/3443 - 4s - loss: 183.7547 - mae: 9.3398 - val_loss: 197.5435 - val_mae: 9.4563 - 4s/epoch - 1ms/step\n",
      "Epoch 101/350\n",
      "3443/3443 - 4s - loss: 183.4728 - mae: 9.3378 - val_loss: 204.3577 - val_mae: 9.7249 - 4s/epoch - 1ms/step\n",
      "Epoch 102/350\n",
      "3443/3443 - 4s - loss: 183.3012 - mae: 9.3405 - val_loss: 196.9582 - val_mae: 9.5146 - 4s/epoch - 1ms/step\n",
      "Epoch 103/350\n",
      "3443/3443 - 3s - loss: 183.5629 - mae: 9.3377 - val_loss: 193.0040 - val_mae: 9.3747 - 3s/epoch - 1ms/step\n",
      "Epoch 104/350\n",
      "3443/3443 - 4s - loss: 183.7566 - mae: 9.3434 - val_loss: 218.5054 - val_mae: 10.0451 - 4s/epoch - 1ms/step\n",
      "Epoch 105/350\n",
      "3443/3443 - 4s - loss: 183.0343 - mae: 9.3291 - val_loss: 192.9722 - val_mae: 9.3607 - 4s/epoch - 1ms/step\n",
      "Epoch 106/350\n",
      "3443/3443 - 4s - loss: 182.5372 - mae: 9.3096 - val_loss: 189.9530 - val_mae: 9.1940 - 4s/epoch - 1ms/step\n",
      "Epoch 107/350\n",
      "3443/3443 - 4s - loss: 183.0437 - mae: 9.3413 - val_loss: 209.4377 - val_mae: 10.0391 - 4s/epoch - 1ms/step\n",
      "Epoch 108/350\n",
      "3443/3443 - 4s - loss: 183.0350 - mae: 9.3362 - val_loss: 191.4818 - val_mae: 9.2690 - 4s/epoch - 1ms/step\n",
      "Epoch 109/350\n",
      "3443/3443 - 4s - loss: 183.0937 - mae: 9.3258 - val_loss: 190.4392 - val_mae: 9.2767 - 4s/epoch - 1ms/step\n",
      "Epoch 110/350\n",
      "3443/3443 - 4s - loss: 182.2851 - mae: 9.2948 - val_loss: 195.6350 - val_mae: 9.5013 - 4s/epoch - 1ms/step\n",
      "Epoch 111/350\n",
      "3443/3443 - 4s - loss: 182.0865 - mae: 9.2871 - val_loss: 201.8964 - val_mae: 9.7184 - 4s/epoch - 1ms/step\n",
      "Epoch 112/350\n",
      "3443/3443 - 4s - loss: 182.4130 - mae: 9.3009 - val_loss: 198.2589 - val_mae: 9.5665 - 4s/epoch - 1ms/step\n",
      "Epoch 113/350\n",
      "3443/3443 - 4s - loss: 182.3602 - mae: 9.3031 - val_loss: 207.8692 - val_mae: 9.8586 - 4s/epoch - 1ms/step\n",
      "Epoch 114/350\n",
      "3443/3443 - 4s - loss: 181.5810 - mae: 9.2802 - val_loss: 196.8872 - val_mae: 9.5419 - 4s/epoch - 1ms/step\n",
      "Epoch 115/350\n",
      "3443/3443 - 4s - loss: 181.9202 - mae: 9.2934 - val_loss: 199.2251 - val_mae: 9.5972 - 4s/epoch - 1ms/step\n",
      "Epoch 116/350\n",
      "3443/3443 - 4s - loss: 182.2365 - mae: 9.2909 - val_loss: 192.6719 - val_mae: 9.3384 - 4s/epoch - 1ms/step\n",
      "Epoch 117/350\n",
      "3443/3443 - 4s - loss: 181.9955 - mae: 9.2942 - val_loss: 194.6922 - val_mae: 9.3265 - 4s/epoch - 1ms/step\n",
      "Epoch 118/350\n",
      "3443/3443 - 4s - loss: 181.1688 - mae: 9.2472 - val_loss: 196.4569 - val_mae: 9.4619 - 4s/epoch - 1ms/step\n",
      "Epoch 119/350\n",
      "3443/3443 - 4s - loss: 181.6405 - mae: 9.2873 - val_loss: 190.7157 - val_mae: 9.2764 - 4s/epoch - 1ms/step\n",
      "Epoch 120/350\n",
      "3443/3443 - 4s - loss: 182.1010 - mae: 9.2919 - val_loss: 192.0986 - val_mae: 9.3548 - 4s/epoch - 1ms/step\n",
      "Epoch 121/350\n",
      "3443/3443 - 4s - loss: 181.2828 - mae: 9.2600 - val_loss: 192.2691 - val_mae: 9.2366 - 4s/epoch - 1ms/step\n",
      "Epoch 122/350\n",
      "3443/3443 - 4s - loss: 181.3950 - mae: 9.2627 - val_loss: 203.3571 - val_mae: 9.6993 - 4s/epoch - 1ms/step\n",
      "Epoch 123/350\n",
      "3443/3443 - 4s - loss: 180.8565 - mae: 9.2459 - val_loss: 203.7868 - val_mae: 9.8228 - 4s/epoch - 1ms/step\n",
      "Epoch 124/350\n",
      "3443/3443 - 4s - loss: 181.2745 - mae: 9.2816 - val_loss: 196.8548 - val_mae: 9.4056 - 4s/epoch - 1ms/step\n",
      "Epoch 125/350\n",
      "3443/3443 - 4s - loss: 180.8183 - mae: 9.2486 - val_loss: 199.6938 - val_mae: 9.6120 - 4s/epoch - 1ms/step\n",
      "Epoch 126/350\n",
      "3443/3443 - 4s - loss: 181.3948 - mae: 9.2736 - val_loss: 196.8762 - val_mae: 9.4868 - 4s/epoch - 1ms/step\n",
      "Epoch 127/350\n",
      "3443/3443 - 4s - loss: 181.0174 - mae: 9.2594 - val_loss: 205.9233 - val_mae: 9.8747 - 4s/epoch - 1ms/step\n",
      "Epoch 128/350\n",
      "3443/3443 - 4s - loss: 180.6775 - mae: 9.2574 - val_loss: 206.1059 - val_mae: 9.7555 - 4s/epoch - 1ms/step\n",
      "Epoch 129/350\n",
      "3443/3443 - 3s - loss: 180.9266 - mae: 9.2688 - val_loss: 196.0253 - val_mae: 9.5167 - 3s/epoch - 1ms/step\n",
      "Epoch 130/350\n",
      "3443/3443 - 4s - loss: 180.6152 - mae: 9.2476 - val_loss: 202.1598 - val_mae: 9.6211 - 4s/epoch - 1ms/step\n",
      "Epoch 131/350\n",
      "3443/3443 - 4s - loss: 180.6773 - mae: 9.2505 - val_loss: 196.4942 - val_mae: 9.4829 - 4s/epoch - 1ms/step\n",
      "Epoch 132/350\n",
      "3443/3443 - 4s - loss: 180.4188 - mae: 9.2469 - val_loss: 209.5365 - val_mae: 9.9204 - 4s/epoch - 1ms/step\n",
      "Epoch 133/350\n",
      "3443/3443 - 3s - loss: 180.6273 - mae: 9.2601 - val_loss: 200.7052 - val_mae: 9.5204 - 3s/epoch - 1ms/step\n",
      "Epoch 134/350\n",
      "3443/3443 - 4s - loss: 179.9823 - mae: 9.2283 - val_loss: 211.6088 - val_mae: 10.0449 - 4s/epoch - 1ms/step\n",
      "Epoch 135/350\n",
      "3443/3443 - 3s - loss: 180.4585 - mae: 9.2479 - val_loss: 191.7802 - val_mae: 9.3501 - 3s/epoch - 1ms/step\n",
      "Epoch 136/350\n",
      "3443/3443 - 4s - loss: 180.1998 - mae: 9.2400 - val_loss: 188.9366 - val_mae: 9.1801 - 4s/epoch - 1ms/step\n",
      "Epoch 137/350\n",
      "3443/3443 - 4s - loss: 179.8286 - mae: 9.2206 - val_loss: 200.3012 - val_mae: 9.7552 - 4s/epoch - 1ms/step\n",
      "Epoch 138/350\n",
      "3443/3443 - 3s - loss: 179.9440 - mae: 9.2338 - val_loss: 195.3120 - val_mae: 9.3084 - 3s/epoch - 1ms/step\n",
      "Epoch 139/350\n",
      "3443/3443 - 4s - loss: 180.7879 - mae: 9.2563 - val_loss: 191.1224 - val_mae: 9.2981 - 4s/epoch - 1ms/step\n",
      "Epoch 140/350\n",
      "3443/3443 - 3s - loss: 179.8281 - mae: 9.2269 - val_loss: 196.9088 - val_mae: 9.5126 - 3s/epoch - 1ms/step\n",
      "Epoch 141/350\n",
      "3443/3443 - 4s - loss: 179.6457 - mae: 9.2271 - val_loss: 197.4422 - val_mae: 9.3923 - 4s/epoch - 1ms/step\n",
      "Epoch 142/350\n",
      "3443/3443 - 4s - loss: 179.3573 - mae: 9.2182 - val_loss: 197.3471 - val_mae: 9.5208 - 4s/epoch - 1ms/step\n",
      "Epoch 143/350\n",
      "3443/3443 - 3s - loss: 179.5442 - mae: 9.2207 - val_loss: 194.5412 - val_mae: 9.4778 - 3s/epoch - 1ms/step\n",
      "Epoch 144/350\n",
      "3443/3443 - 4s - loss: 179.2380 - mae: 9.2244 - val_loss: 192.9874 - val_mae: 9.2574 - 4s/epoch - 1ms/step\n",
      "Epoch 145/350\n",
      "3443/3443 - 4s - loss: 179.1250 - mae: 9.1963 - val_loss: 198.5434 - val_mae: 9.6007 - 4s/epoch - 1ms/step\n",
      "Epoch 146/350\n",
      "3443/3443 - 4s - loss: 179.0723 - mae: 9.2046 - val_loss: 198.9181 - val_mae: 9.5605 - 4s/epoch - 1ms/step\n",
      "Epoch 147/350\n",
      "3443/3443 - 4s - loss: 179.4025 - mae: 9.2172 - val_loss: 193.8260 - val_mae: 9.2894 - 4s/epoch - 1ms/step\n",
      "Epoch 148/350\n",
      "3443/3443 - 3s - loss: 179.5827 - mae: 9.2179 - val_loss: 188.7329 - val_mae: 9.1547 - 3s/epoch - 1ms/step\n",
      "Epoch 149/350\n",
      "3443/3443 - 3s - loss: 179.3262 - mae: 9.2124 - val_loss: 193.9540 - val_mae: 9.3688 - 3s/epoch - 1ms/step\n",
      "Epoch 150/350\n",
      "3443/3443 - 4s - loss: 179.0747 - mae: 9.2075 - val_loss: 218.2355 - val_mae: 10.4839 - 4s/epoch - 1ms/step\n",
      "Epoch 151/350\n",
      "3443/3443 - 4s - loss: 179.0914 - mae: 9.2095 - val_loss: 190.1862 - val_mae: 9.2328 - 4s/epoch - 1ms/step\n",
      "Epoch 152/350\n",
      "3443/3443 - 4s - loss: 178.8105 - mae: 9.2000 - val_loss: 191.3237 - val_mae: 9.4130 - 4s/epoch - 1ms/step\n",
      "Epoch 153/350\n",
      "3443/3443 - 3s - loss: 178.5316 - mae: 9.1920 - val_loss: 189.9279 - val_mae: 9.1973 - 3s/epoch - 1ms/step\n",
      "Epoch 154/350\n",
      "3443/3443 - 4s - loss: 179.0700 - mae: 9.2088 - val_loss: 191.4805 - val_mae: 9.2442 - 4s/epoch - 1ms/step\n",
      "Epoch 155/350\n",
      "3443/3443 - 4s - loss: 178.4830 - mae: 9.1852 - val_loss: 188.8350 - val_mae: 9.1572 - 4s/epoch - 1ms/step\n",
      "Epoch 156/350\n",
      "3443/3443 - 4s - loss: 178.4788 - mae: 9.1895 - val_loss: 188.1703 - val_mae: 9.2322 - 4s/epoch - 1ms/step\n",
      "Epoch 157/350\n",
      "3443/3443 - 4s - loss: 178.2721 - mae: 9.1808 - val_loss: 189.4810 - val_mae: 9.2471 - 4s/epoch - 1ms/step\n",
      "Epoch 158/350\n",
      "3443/3443 - 4s - loss: 178.6956 - mae: 9.1935 - val_loss: 189.6417 - val_mae: 9.1617 - 4s/epoch - 1ms/step\n",
      "Epoch 159/350\n",
      "3443/3443 - 4s - loss: 178.7221 - mae: 9.2006 - val_loss: 190.6591 - val_mae: 9.2893 - 4s/epoch - 1ms/step\n",
      "Epoch 160/350\n",
      "3443/3443 - 4s - loss: 178.8239 - mae: 9.1956 - val_loss: 190.4119 - val_mae: 9.2822 - 4s/epoch - 1ms/step\n",
      "Epoch 161/350\n",
      "3443/3443 - 4s - loss: 178.8275 - mae: 9.2000 - val_loss: 194.9568 - val_mae: 9.2827 - 4s/epoch - 1ms/step\n",
      "Epoch 162/350\n",
      "3443/3443 - 4s - loss: 178.3042 - mae: 9.1846 - val_loss: 185.9582 - val_mae: 9.0544 - 4s/epoch - 1ms/step\n",
      "Epoch 163/350\n",
      "3443/3443 - 4s - loss: 178.6805 - mae: 9.1940 - val_loss: 189.4120 - val_mae: 9.1922 - 4s/epoch - 1ms/step\n",
      "Epoch 164/350\n",
      "3443/3443 - 4s - loss: 177.8839 - mae: 9.1739 - val_loss: 191.3142 - val_mae: 9.2394 - 4s/epoch - 1ms/step\n",
      "Epoch 165/350\n",
      "3443/3443 - 4s - loss: 178.3448 - mae: 9.1937 - val_loss: 208.6294 - val_mae: 10.1777 - 4s/epoch - 1ms/step\n",
      "Epoch 166/350\n",
      "3443/3443 - 4s - loss: 178.3702 - mae: 9.1990 - val_loss: 194.3279 - val_mae: 9.4234 - 4s/epoch - 1ms/step\n",
      "Epoch 167/350\n",
      "3443/3443 - 4s - loss: 178.2838 - mae: 9.1840 - val_loss: 205.0603 - val_mae: 9.8045 - 4s/epoch - 1ms/step\n",
      "Epoch 168/350\n",
      "3443/3443 - 4s - loss: 177.6738 - mae: 9.1705 - val_loss: 199.7264 - val_mae: 9.7374 - 4s/epoch - 1ms/step\n",
      "Epoch 169/350\n",
      "3443/3443 - 4s - loss: 177.8449 - mae: 9.1728 - val_loss: 193.4617 - val_mae: 9.4106 - 4s/epoch - 1ms/step\n",
      "Epoch 170/350\n",
      "3443/3443 - 4s - loss: 177.7476 - mae: 9.1713 - val_loss: 193.5554 - val_mae: 9.3580 - 4s/epoch - 1ms/step\n",
      "Epoch 171/350\n",
      "3443/3443 - 4s - loss: 177.6528 - mae: 9.1606 - val_loss: 190.4128 - val_mae: 9.2207 - 4s/epoch - 1ms/step\n",
      "Epoch 172/350\n",
      "3443/3443 - 4s - loss: 177.6076 - mae: 9.1625 - val_loss: 190.0845 - val_mae: 9.2253 - 4s/epoch - 1ms/step\n",
      "Epoch 173/350\n",
      "3443/3443 - 4s - loss: 177.3594 - mae: 9.1503 - val_loss: 195.8265 - val_mae: 9.6256 - 4s/epoch - 1ms/step\n",
      "Epoch 174/350\n",
      "3443/3443 - 4s - loss: 177.7706 - mae: 9.1776 - val_loss: 192.6477 - val_mae: 9.3807 - 4s/epoch - 1ms/step\n",
      "Epoch 175/350\n",
      "3443/3443 - 3s - loss: 177.6000 - mae: 9.1597 - val_loss: 190.1451 - val_mae: 9.2337 - 3s/epoch - 1ms/step\n",
      "Epoch 176/350\n",
      "3443/3443 - 4s - loss: 177.4710 - mae: 9.1577 - val_loss: 190.7254 - val_mae: 9.2515 - 4s/epoch - 1ms/step\n",
      "Epoch 177/350\n",
      "3443/3443 - 4s - loss: 176.7186 - mae: 9.1148 - val_loss: 197.4340 - val_mae: 9.3221 - 4s/epoch - 1ms/step\n",
      "Epoch 178/350\n",
      "3443/3443 - 4s - loss: 177.7012 - mae: 9.1560 - val_loss: 196.2563 - val_mae: 9.5630 - 4s/epoch - 1ms/step\n",
      "Epoch 179/350\n",
      "3443/3443 - 4s - loss: 177.7847 - mae: 9.1752 - val_loss: 197.5815 - val_mae: 9.6011 - 4s/epoch - 1ms/step\n",
      "Epoch 180/350\n",
      "3443/3443 - 4s - loss: 177.0202 - mae: 9.1510 - val_loss: 192.7304 - val_mae: 9.4167 - 4s/epoch - 1ms/step\n",
      "Epoch 181/350\n",
      "3443/3443 - 4s - loss: 176.7245 - mae: 9.1183 - val_loss: 197.8143 - val_mae: 9.4936 - 4s/epoch - 1ms/step\n",
      "Epoch 182/350\n",
      "3443/3443 - 4s - loss: 177.0737 - mae: 9.1500 - val_loss: 192.5576 - val_mae: 9.4048 - 4s/epoch - 1ms/step\n",
      "Epoch 183/350\n",
      "3443/3443 - 4s - loss: 176.5058 - mae: 9.1237 - val_loss: 196.0488 - val_mae: 9.5177 - 4s/epoch - 1ms/step\n",
      "Epoch 184/350\n",
      "3443/3443 - 3s - loss: 176.8547 - mae: 9.1413 - val_loss: 196.2072 - val_mae: 9.6370 - 3s/epoch - 1ms/step\n",
      "Epoch 185/350\n",
      "3443/3443 - 4s - loss: 176.6022 - mae: 9.1275 - val_loss: 203.6995 - val_mae: 9.9599 - 4s/epoch - 1ms/step\n",
      "Epoch 186/350\n",
      "3443/3443 - 4s - loss: 177.0154 - mae: 9.1462 - val_loss: 190.2216 - val_mae: 9.2712 - 4s/epoch - 1ms/step\n",
      "Epoch 187/350\n",
      "3443/3443 - 4s - loss: 176.6998 - mae: 9.1388 - val_loss: 189.8126 - val_mae: 9.2580 - 4s/epoch - 1ms/step\n",
      "Epoch 188/350\n",
      "3443/3443 - 4s - loss: 176.9326 - mae: 9.1466 - val_loss: 189.1043 - val_mae: 9.1459 - 4s/epoch - 1ms/step\n",
      "Epoch 189/350\n",
      "3443/3443 - 4s - loss: 177.1627 - mae: 9.1489 - val_loss: 192.2132 - val_mae: 9.3330 - 4s/epoch - 1ms/step\n",
      "Epoch 190/350\n",
      "3443/3443 - 4s - loss: 176.8344 - mae: 9.1444 - val_loss: 195.0100 - val_mae: 9.3921 - 4s/epoch - 1ms/step\n",
      "Epoch 191/350\n",
      "3443/3443 - 4s - loss: 176.3305 - mae: 9.1200 - val_loss: 198.6037 - val_mae: 9.5368 - 4s/epoch - 1ms/step\n",
      "Epoch 192/350\n",
      "3443/3443 - 4s - loss: 176.2139 - mae: 9.1199 - val_loss: 189.7867 - val_mae: 9.0955 - 4s/epoch - 1ms/step\n",
      "Epoch 193/350\n",
      "3443/3443 - 4s - loss: 176.7494 - mae: 9.1296 - val_loss: 193.6162 - val_mae: 9.3834 - 4s/epoch - 1ms/step\n",
      "Epoch 194/350\n",
      "3443/3443 - 4s - loss: 176.5711 - mae: 9.1295 - val_loss: 189.3031 - val_mae: 9.2364 - 4s/epoch - 1ms/step\n",
      "Epoch 195/350\n",
      "3443/3443 - 4s - loss: 176.3685 - mae: 9.1254 - val_loss: 189.9209 - val_mae: 9.3549 - 4s/epoch - 1ms/step\n",
      "Epoch 196/350\n",
      "3443/3443 - 4s - loss: 176.5864 - mae: 9.1226 - val_loss: 192.6653 - val_mae: 9.2194 - 4s/epoch - 1ms/step\n",
      "Epoch 197/350\n",
      "3443/3443 - 4s - loss: 176.3731 - mae: 9.1254 - val_loss: 205.0670 - val_mae: 9.7045 - 4s/epoch - 1ms/step\n",
      "Epoch 198/350\n",
      "3443/3443 - 4s - loss: 176.2677 - mae: 9.1156 - val_loss: 186.3085 - val_mae: 9.1117 - 4s/epoch - 1ms/step\n",
      "Epoch 199/350\n",
      "3443/3443 - 4s - loss: 176.4705 - mae: 9.1309 - val_loss: 193.0005 - val_mae: 9.2543 - 4s/epoch - 1ms/step\n",
      "Epoch 200/350\n",
      "3443/3443 - 4s - loss: 175.8624 - mae: 9.1161 - val_loss: 188.9329 - val_mae: 9.2645 - 4s/epoch - 1ms/step\n",
      "Epoch 201/350\n",
      "3443/3443 - 4s - loss: 176.1874 - mae: 9.1136 - val_loss: 191.0003 - val_mae: 9.2385 - 4s/epoch - 1ms/step\n",
      "Epoch 202/350\n",
      "3443/3443 - 4s - loss: 175.8262 - mae: 9.1063 - val_loss: 188.7320 - val_mae: 9.1756 - 4s/epoch - 1ms/step\n",
      "Epoch 203/350\n",
      "3443/3443 - 4s - loss: 176.1990 - mae: 9.1157 - val_loss: 192.8201 - val_mae: 9.4239 - 4s/epoch - 1ms/step\n",
      "Epoch 204/350\n",
      "3443/3443 - 4s - loss: 175.8646 - mae: 9.1124 - val_loss: 188.7899 - val_mae: 9.1351 - 4s/epoch - 1ms/step\n",
      "Epoch 205/350\n",
      "3443/3443 - 4s - loss: 176.0985 - mae: 9.1103 - val_loss: 188.3623 - val_mae: 9.1428 - 4s/epoch - 1ms/step\n",
      "Epoch 206/350\n",
      "3443/3443 - 4s - loss: 176.1619 - mae: 9.1251 - val_loss: 191.2744 - val_mae: 9.2614 - 4s/epoch - 1ms/step\n",
      "Epoch 207/350\n",
      "3443/3443 - 4s - loss: 176.0621 - mae: 9.1074 - val_loss: 190.5793 - val_mae: 9.2610 - 4s/epoch - 1ms/step\n",
      "Epoch 208/350\n",
      "3443/3443 - 4s - loss: 175.6315 - mae: 9.1031 - val_loss: 194.6817 - val_mae: 9.4521 - 4s/epoch - 1ms/step\n",
      "Epoch 209/350\n",
      "3443/3443 - 4s - loss: 176.1088 - mae: 9.1274 - val_loss: 185.9472 - val_mae: 9.0829 - 4s/epoch - 1ms/step\n",
      "Epoch 210/350\n",
      "3443/3443 - 4s - loss: 175.8805 - mae: 9.1073 - val_loss: 190.0342 - val_mae: 9.2532 - 4s/epoch - 1ms/step\n",
      "Epoch 211/350\n",
      "3443/3443 - 4s - loss: 175.8387 - mae: 9.1127 - val_loss: 230.7678 - val_mae: 10.8776 - 4s/epoch - 1ms/step\n",
      "Epoch 212/350\n",
      "3443/3443 - 4s - loss: 175.5647 - mae: 9.1007 - val_loss: 192.2182 - val_mae: 9.4093 - 4s/epoch - 1ms/step\n",
      "Epoch 213/350\n",
      "3443/3443 - 4s - loss: 175.1562 - mae: 9.0823 - val_loss: 198.1762 - val_mae: 9.3178 - 4s/epoch - 1ms/step\n",
      "Epoch 214/350\n",
      "3443/3443 - 4s - loss: 175.8337 - mae: 9.1159 - val_loss: 188.0235 - val_mae: 9.2311 - 4s/epoch - 1ms/step\n",
      "Epoch 215/350\n",
      "3443/3443 - 4s - loss: 175.4686 - mae: 9.0957 - val_loss: 187.4371 - val_mae: 9.0442 - 4s/epoch - 1ms/step\n",
      "Epoch 216/350\n",
      "3443/3443 - 4s - loss: 175.1101 - mae: 9.0831 - val_loss: 187.3762 - val_mae: 9.1050 - 4s/epoch - 1ms/step\n",
      "Epoch 217/350\n",
      "3443/3443 - 4s - loss: 175.7149 - mae: 9.0948 - val_loss: 200.9108 - val_mae: 9.6433 - 4s/epoch - 1ms/step\n",
      "Epoch 218/350\n",
      "3443/3443 - 4s - loss: 175.1887 - mae: 9.0833 - val_loss: 188.5128 - val_mae: 9.1811 - 4s/epoch - 1ms/step\n",
      "Epoch 219/350\n",
      "3443/3443 - 4s - loss: 175.4501 - mae: 9.1096 - val_loss: 189.4540 - val_mae: 9.2305 - 4s/epoch - 1ms/step\n",
      "Epoch 220/350\n",
      "3443/3443 - 4s - loss: 175.1817 - mae: 9.0832 - val_loss: 191.7669 - val_mae: 9.3009 - 4s/epoch - 1ms/step\n",
      "Epoch 221/350\n",
      "3443/3443 - 4s - loss: 175.2527 - mae: 9.0967 - val_loss: 189.3149 - val_mae: 9.2406 - 4s/epoch - 1ms/step\n",
      "Epoch 222/350\n",
      "3443/3443 - 4s - loss: 174.9828 - mae: 9.0795 - val_loss: 189.9348 - val_mae: 9.2259 - 4s/epoch - 1ms/step\n",
      "Epoch 223/350\n",
      "3443/3443 - 4s - loss: 175.2248 - mae: 9.0826 - val_loss: 186.1373 - val_mae: 9.0578 - 4s/epoch - 1ms/step\n",
      "Epoch 224/350\n",
      "3443/3443 - 4s - loss: 175.2221 - mae: 9.0935 - val_loss: 194.1779 - val_mae: 9.3862 - 4s/epoch - 1ms/step\n",
      "Epoch 225/350\n",
      "3443/3443 - 4s - loss: 175.1969 - mae: 9.0915 - val_loss: 203.0978 - val_mae: 9.8725 - 4s/epoch - 1ms/step\n",
      "Epoch 226/350\n",
      "3443/3443 - 4s - loss: 175.4350 - mae: 9.0874 - val_loss: 187.1364 - val_mae: 9.1873 - 4s/epoch - 1ms/step\n",
      "Epoch 227/350\n",
      "3443/3443 - 4s - loss: 174.4496 - mae: 9.0702 - val_loss: 183.8387 - val_mae: 8.9956 - 4s/epoch - 1ms/step\n",
      "Epoch 228/350\n",
      "3443/3443 - 4s - loss: 175.4998 - mae: 9.0904 - val_loss: 189.8079 - val_mae: 9.2530 - 4s/epoch - 1ms/step\n",
      "Epoch 229/350\n",
      "3443/3443 - 4s - loss: 175.1663 - mae: 9.0928 - val_loss: 186.8149 - val_mae: 9.1947 - 4s/epoch - 1ms/step\n",
      "Epoch 230/350\n",
      "3443/3443 - 4s - loss: 174.3648 - mae: 9.0614 - val_loss: 200.6481 - val_mae: 9.8038 - 4s/epoch - 1ms/step\n",
      "Epoch 231/350\n",
      "3443/3443 - 4s - loss: 174.7938 - mae: 9.0786 - val_loss: 190.8547 - val_mae: 9.2779 - 4s/epoch - 1ms/step\n",
      "Epoch 232/350\n",
      "3443/3443 - 7s - loss: 174.7828 - mae: 9.0891 - val_loss: 201.9625 - val_mae: 9.8043 - 7s/epoch - 2ms/step\n",
      "Epoch 233/350\n",
      "3443/3443 - 4s - loss: 174.7267 - mae: 9.0635 - val_loss: 190.1880 - val_mae: 9.2666 - 4s/epoch - 1ms/step\n",
      "Epoch 234/350\n",
      "3443/3443 - 4s - loss: 175.3907 - mae: 9.1048 - val_loss: 195.7921 - val_mae: 9.3783 - 4s/epoch - 1ms/step\n",
      "Epoch 235/350\n",
      "3443/3443 - 6s - loss: 174.7204 - mae: 9.0772 - val_loss: 195.4379 - val_mae: 9.5486 - 6s/epoch - 2ms/step\n",
      "Epoch 236/350\n",
      "3443/3443 - 5s - loss: 174.7482 - mae: 9.0866 - val_loss: 185.5566 - val_mae: 9.0617 - 5s/epoch - 1ms/step\n",
      "Epoch 237/350\n",
      "3443/3443 - 4s - loss: 174.2895 - mae: 9.0610 - val_loss: 190.7650 - val_mae: 9.2214 - 4s/epoch - 1ms/step\n",
      "Epoch 238/350\n",
      "3443/3443 - 4s - loss: 174.3891 - mae: 9.0617 - val_loss: 183.7801 - val_mae: 9.0356 - 4s/epoch - 1ms/step\n",
      "Epoch 239/350\n",
      "3443/3443 - 4s - loss: 174.5217 - mae: 9.0682 - val_loss: 193.1431 - val_mae: 9.2387 - 4s/epoch - 1ms/step\n",
      "Epoch 240/350\n",
      "3443/3443 - 4s - loss: 174.8404 - mae: 9.0775 - val_loss: 192.1999 - val_mae: 9.3493 - 4s/epoch - 1ms/step\n",
      "Epoch 241/350\n",
      "3443/3443 - 4s - loss: 174.5483 - mae: 9.0607 - val_loss: 188.4990 - val_mae: 9.1740 - 4s/epoch - 1ms/step\n",
      "Epoch 242/350\n",
      "3443/3443 - 4s - loss: 174.3547 - mae: 9.0558 - val_loss: 187.2458 - val_mae: 9.1507 - 4s/epoch - 1ms/step\n",
      "Epoch 243/350\n",
      "3443/3443 - 4s - loss: 174.1559 - mae: 9.0607 - val_loss: 192.7054 - val_mae: 9.2081 - 4s/epoch - 1ms/step\n",
      "Epoch 244/350\n",
      "3443/3443 - 4s - loss: 173.8709 - mae: 9.0595 - val_loss: 194.1112 - val_mae: 9.3778 - 4s/epoch - 1ms/step\n",
      "Epoch 245/350\n",
      "3443/3443 - 4s - loss: 174.4907 - mae: 9.0725 - val_loss: 217.9037 - val_mae: 10.3519 - 4s/epoch - 1ms/step\n",
      "Epoch 246/350\n",
      "3443/3443 - 4s - loss: 174.4299 - mae: 9.0646 - val_loss: 194.5221 - val_mae: 9.3140 - 4s/epoch - 1ms/step\n",
      "Epoch 247/350\n",
      "3443/3443 - 4s - loss: 174.6382 - mae: 9.0614 - val_loss: 189.0618 - val_mae: 9.2639 - 4s/epoch - 1ms/step\n",
      "Epoch 248/350\n",
      "3443/3443 - 4s - loss: 174.0752 - mae: 9.0553 - val_loss: 188.2132 - val_mae: 9.2207 - 4s/epoch - 1ms/step\n",
      "Epoch 249/350\n",
      "3443/3443 - 4s - loss: 174.2573 - mae: 9.0541 - val_loss: 199.8607 - val_mae: 9.7196 - 4s/epoch - 1ms/step\n",
      "Epoch 250/350\n",
      "3443/3443 - 4s - loss: 174.0493 - mae: 9.0553 - val_loss: 183.6416 - val_mae: 8.9516 - 4s/epoch - 1ms/step\n",
      "Epoch 251/350\n",
      "3443/3443 - 4s - loss: 174.2914 - mae: 9.0657 - val_loss: 194.2957 - val_mae: 9.3897 - 4s/epoch - 1ms/step\n",
      "Epoch 252/350\n",
      "3443/3443 - 4s - loss: 173.6629 - mae: 9.0294 - val_loss: 189.0798 - val_mae: 9.1796 - 4s/epoch - 1ms/step\n",
      "Epoch 253/350\n",
      "3443/3443 - 4s - loss: 173.9637 - mae: 9.0488 - val_loss: 197.1482 - val_mae: 9.4019 - 4s/epoch - 1ms/step\n",
      "Epoch 254/350\n",
      "3443/3443 - 4s - loss: 173.9187 - mae: 9.0357 - val_loss: 186.5753 - val_mae: 9.0111 - 4s/epoch - 1ms/step\n",
      "Epoch 255/350\n",
      "3443/3443 - 4s - loss: 173.9897 - mae: 9.0491 - val_loss: 190.4624 - val_mae: 9.2378 - 4s/epoch - 1ms/step\n",
      "Epoch 256/350\n",
      "3443/3443 - 4s - loss: 173.7855 - mae: 9.0381 - val_loss: 199.6223 - val_mae: 9.4088 - 4s/epoch - 1ms/step\n",
      "Epoch 257/350\n",
      "3443/3443 - 4s - loss: 173.9197 - mae: 9.0491 - val_loss: 186.2988 - val_mae: 9.1094 - 4s/epoch - 1ms/step\n",
      "Epoch 258/350\n",
      "3443/3443 - 4s - loss: 174.0307 - mae: 9.0584 - val_loss: 188.5638 - val_mae: 9.2160 - 4s/epoch - 1ms/step\n",
      "Epoch 259/350\n",
      "3443/3443 - 3s - loss: 173.1694 - mae: 9.0267 - val_loss: 186.9144 - val_mae: 9.1405 - 3s/epoch - 1ms/step\n",
      "Epoch 260/350\n",
      "3443/3443 - 4s - loss: 173.8040 - mae: 9.0394 - val_loss: 192.9095 - val_mae: 9.4426 - 4s/epoch - 1ms/step\n",
      "Epoch 261/350\n",
      "3443/3443 - 3s - loss: 173.3524 - mae: 9.0318 - val_loss: 194.4240 - val_mae: 9.3596 - 3s/epoch - 1ms/step\n",
      "Epoch 262/350\n",
      "3443/3443 - 4s - loss: 174.4674 - mae: 9.0672 - val_loss: 192.4259 - val_mae: 9.3262 - 4s/epoch - 1ms/step\n",
      "Epoch 263/350\n",
      "3443/3443 - 4s - loss: 172.8955 - mae: 8.9969 - val_loss: 195.2110 - val_mae: 9.3911 - 4s/epoch - 1ms/step\n",
      "Epoch 264/350\n",
      "3443/3443 - 3s - loss: 173.4569 - mae: 9.0259 - val_loss: 185.4209 - val_mae: 9.1028 - 3s/epoch - 1ms/step\n",
      "Epoch 265/350\n",
      "3443/3443 - 4s - loss: 173.6192 - mae: 9.0267 - val_loss: 189.0126 - val_mae: 9.1842 - 4s/epoch - 1ms/step\n",
      "Epoch 266/350\n",
      "3443/3443 - 4s - loss: 173.5753 - mae: 9.0356 - val_loss: 202.3131 - val_mae: 9.8460 - 4s/epoch - 1ms/step\n",
      "Epoch 267/350\n",
      "3443/3443 - 4s - loss: 173.5816 - mae: 9.0321 - val_loss: 188.4440 - val_mae: 9.1816 - 4s/epoch - 1ms/step\n",
      "Epoch 268/350\n",
      "3443/3443 - 3s - loss: 173.3243 - mae: 9.0223 - val_loss: 190.6914 - val_mae: 9.3611 - 3s/epoch - 1ms/step\n",
      "Epoch 269/350\n",
      "3443/3443 - 4s - loss: 173.2034 - mae: 9.0177 - val_loss: 193.5624 - val_mae: 9.2939 - 4s/epoch - 1ms/step\n",
      "Epoch 270/350\n",
      "3443/3443 - 4s - loss: 173.2745 - mae: 9.0184 - val_loss: 182.9373 - val_mae: 8.9842 - 4s/epoch - 1ms/step\n",
      "Epoch 271/350\n",
      "3443/3443 - 3s - loss: 173.6846 - mae: 9.0364 - val_loss: 188.0760 - val_mae: 9.1749 - 3s/epoch - 1ms/step\n",
      "Epoch 272/350\n",
      "3443/3443 - 4s - loss: 173.6862 - mae: 9.0380 - val_loss: 190.2774 - val_mae: 9.1745 - 4s/epoch - 1ms/step\n",
      "Epoch 273/350\n",
      "3443/3443 - 3s - loss: 172.6904 - mae: 9.0067 - val_loss: 193.2358 - val_mae: 9.3495 - 3s/epoch - 1ms/step\n",
      "Epoch 274/350\n",
      "3443/3443 - 4s - loss: 173.2925 - mae: 9.0164 - val_loss: 184.8811 - val_mae: 9.0951 - 4s/epoch - 1ms/step\n",
      "Epoch 275/350\n",
      "3443/3443 - 4s - loss: 173.5444 - mae: 9.0403 - val_loss: 190.2220 - val_mae: 9.3112 - 4s/epoch - 1ms/step\n",
      "Epoch 276/350\n",
      "3443/3443 - 4s - loss: 173.0144 - mae: 9.0132 - val_loss: 186.3945 - val_mae: 9.0568 - 4s/epoch - 1ms/step\n",
      "Epoch 277/350\n",
      "3443/3443 - 4s - loss: 173.1546 - mae: 9.0260 - val_loss: 188.7862 - val_mae: 9.1238 - 4s/epoch - 1ms/step\n",
      "Epoch 278/350\n",
      "3443/3443 - 3s - loss: 173.0336 - mae: 9.0182 - val_loss: 183.1502 - val_mae: 8.9526 - 3s/epoch - 1ms/step\n",
      "Epoch 279/350\n",
      "3443/3443 - 4s - loss: 172.8364 - mae: 9.0242 - val_loss: 192.5482 - val_mae: 9.3863 - 4s/epoch - 1ms/step\n",
      "Epoch 280/350\n",
      "3443/3443 - 4s - loss: 173.1694 - mae: 9.0135 - val_loss: 200.0197 - val_mae: 9.6210 - 4s/epoch - 1ms/step\n",
      "Epoch 281/350\n",
      "3443/3443 - 3s - loss: 173.1673 - mae: 9.0297 - val_loss: 184.7247 - val_mae: 9.0175 - 3s/epoch - 1ms/step\n",
      "Epoch 282/350\n",
      "3443/3443 - 4s - loss: 172.5915 - mae: 9.0037 - val_loss: 183.6561 - val_mae: 8.9565 - 4s/epoch - 1ms/step\n",
      "Epoch 283/350\n",
      "3443/3443 - 4s - loss: 173.1549 - mae: 9.0207 - val_loss: 185.3106 - val_mae: 9.1038 - 4s/epoch - 1ms/step\n",
      "Epoch 284/350\n",
      "3443/3443 - 5s - loss: 172.8419 - mae: 9.0030 - val_loss: 186.9466 - val_mae: 9.1165 - 5s/epoch - 1ms/step\n",
      "Epoch 285/350\n",
      "3443/3443 - 4s - loss: 172.7652 - mae: 9.0169 - val_loss: 186.8286 - val_mae: 9.1412 - 4s/epoch - 1ms/step\n",
      "Epoch 286/350\n",
      "3443/3443 - 3s - loss: 173.0094 - mae: 9.0126 - val_loss: 192.2952 - val_mae: 9.4094 - 3s/epoch - 1ms/step\n",
      "Epoch 287/350\n",
      "3443/3443 - 4s - loss: 172.9328 - mae: 9.0121 - val_loss: 187.5522 - val_mae: 9.1820 - 4s/epoch - 1ms/step\n",
      "Epoch 288/350\n",
      "3443/3443 - 3s - loss: 172.8781 - mae: 9.0053 - val_loss: 190.7035 - val_mae: 9.2630 - 3s/epoch - 1ms/step\n",
      "Epoch 289/350\n",
      "3443/3443 - 4s - loss: 172.5112 - mae: 9.0147 - val_loss: 188.9219 - val_mae: 9.2924 - 4s/epoch - 1ms/step\n",
      "Epoch 290/350\n",
      "3443/3443 - 4s - loss: 173.2635 - mae: 9.0315 - val_loss: 195.5762 - val_mae: 9.4658 - 4s/epoch - 1ms/step\n",
      "Epoch 291/350\n",
      "3443/3443 - 4s - loss: 172.0909 - mae: 8.9831 - val_loss: 188.1400 - val_mae: 9.1270 - 4s/epoch - 1ms/step\n",
      "Epoch 292/350\n",
      "3443/3443 - 4s - loss: 172.5062 - mae: 8.9984 - val_loss: 188.1884 - val_mae: 9.1022 - 4s/epoch - 1ms/step\n",
      "Epoch 293/350\n",
      "3443/3443 - 4s - loss: 172.8704 - mae: 9.0200 - val_loss: 193.9845 - val_mae: 9.4739 - 4s/epoch - 1ms/step\n",
      "Epoch 294/350\n",
      "3443/3443 - 3s - loss: 172.8575 - mae: 9.0087 - val_loss: 195.0096 - val_mae: 9.5818 - 3s/epoch - 1ms/step\n",
      "Epoch 295/350\n",
      "3443/3443 - 3s - loss: 173.0958 - mae: 9.0248 - val_loss: 187.0167 - val_mae: 9.1614 - 3s/epoch - 1ms/step\n",
      "Epoch 296/350\n",
      "3443/3443 - 3s - loss: 172.2705 - mae: 9.0029 - val_loss: 188.2228 - val_mae: 9.1453 - 3s/epoch - 1ms/step\n",
      "Epoch 297/350\n",
      "3443/3443 - 3s - loss: 172.4628 - mae: 9.0020 - val_loss: 197.4000 - val_mae: 9.4168 - 3s/epoch - 1ms/step\n",
      "Epoch 298/350\n",
      "3443/3443 - 4s - loss: 172.3031 - mae: 9.0002 - val_loss: 204.2916 - val_mae: 9.9420 - 4s/epoch - 1ms/step\n",
      "Epoch 299/350\n",
      "3443/3443 - 4s - loss: 172.8812 - mae: 9.0258 - val_loss: 197.8445 - val_mae: 9.5165 - 4s/epoch - 1ms/step\n",
      "Epoch 300/350\n",
      "3443/3443 - 4s - loss: 171.6100 - mae: 8.9814 - val_loss: 186.1098 - val_mae: 9.0581 - 4s/epoch - 1ms/step\n",
      "Epoch 301/350\n",
      "3443/3443 - 4s - loss: 172.3335 - mae: 8.9962 - val_loss: 188.8657 - val_mae: 9.2698 - 4s/epoch - 1ms/step\n",
      "Epoch 302/350\n",
      "3443/3443 - 4s - loss: 172.3662 - mae: 9.0011 - val_loss: 187.2814 - val_mae: 9.1101 - 4s/epoch - 1ms/step\n",
      "Epoch 303/350\n",
      "3443/3443 - 4s - loss: 172.2891 - mae: 8.9958 - val_loss: 197.9596 - val_mae: 9.6275 - 4s/epoch - 1ms/step\n",
      "Epoch 304/350\n",
      "3443/3443 - 4s - loss: 172.2471 - mae: 8.9993 - val_loss: 190.2737 - val_mae: 9.1558 - 4s/epoch - 1ms/step\n",
      "Epoch 305/350\n",
      "3443/3443 - 3s - loss: 171.8419 - mae: 8.9782 - val_loss: 193.3674 - val_mae: 9.3482 - 3s/epoch - 1ms/step\n",
      "Epoch 306/350\n",
      "3443/3443 - 4s - loss: 172.2088 - mae: 8.9916 - val_loss: 185.4828 - val_mae: 9.0508 - 4s/epoch - 1ms/step\n",
      "Epoch 307/350\n",
      "3443/3443 - 4s - loss: 172.6953 - mae: 9.0146 - val_loss: 183.5831 - val_mae: 8.9663 - 4s/epoch - 1ms/step\n",
      "Epoch 308/350\n",
      "3443/3443 - 4s - loss: 172.2168 - mae: 8.9990 - val_loss: 205.1946 - val_mae: 9.8782 - 4s/epoch - 1ms/step\n",
      "Epoch 309/350\n",
      "3443/3443 - 4s - loss: 171.9404 - mae: 8.9801 - val_loss: 194.0241 - val_mae: 9.4542 - 4s/epoch - 1ms/step\n",
      "Epoch 310/350\n",
      "3443/3443 - 4s - loss: 172.6066 - mae: 9.0010 - val_loss: 184.9514 - val_mae: 9.0253 - 4s/epoch - 1ms/step\n",
      "Epoch 311/350\n",
      "3443/3443 - 3s - loss: 172.4021 - mae: 9.0047 - val_loss: 185.6667 - val_mae: 9.0772 - 3s/epoch - 1ms/step\n",
      "Epoch 312/350\n",
      "3443/3443 - 4s - loss: 172.2901 - mae: 8.9963 - val_loss: 202.9780 - val_mae: 9.9188 - 4s/epoch - 1ms/step\n",
      "Epoch 313/350\n",
      "3443/3443 - 4s - loss: 171.6668 - mae: 8.9701 - val_loss: 190.8820 - val_mae: 9.2892 - 4s/epoch - 1ms/step\n",
      "Epoch 314/350\n",
      "3443/3443 - 4s - loss: 171.6216 - mae: 8.9581 - val_loss: 191.1736 - val_mae: 9.3098 - 4s/epoch - 1ms/step\n",
      "Epoch 315/350\n",
      "3443/3443 - 4s - loss: 172.1103 - mae: 8.9955 - val_loss: 190.7396 - val_mae: 9.2068 - 4s/epoch - 1ms/step\n",
      "Epoch 316/350\n",
      "3443/3443 - 4s - loss: 172.2997 - mae: 8.9992 - val_loss: 184.8298 - val_mae: 9.0224 - 4s/epoch - 1ms/step\n",
      "Epoch 317/350\n",
      "3443/3443 - 4s - loss: 172.5598 - mae: 8.9995 - val_loss: 200.6346 - val_mae: 9.7613 - 4s/epoch - 1ms/step\n",
      "Epoch 318/350\n",
      "3443/3443 - 4s - loss: 171.7374 - mae: 8.9758 - val_loss: 190.3093 - val_mae: 9.1791 - 4s/epoch - 1ms/step\n",
      "Epoch 319/350\n",
      "3443/3443 - 4s - loss: 171.8651 - mae: 8.9814 - val_loss: 185.7463 - val_mae: 9.0976 - 4s/epoch - 1ms/step\n",
      "Epoch 320/350\n",
      "3443/3443 - 4s - loss: 171.7457 - mae: 8.9840 - val_loss: 185.8557 - val_mae: 9.0491 - 4s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=350,\n",
    "    batch_size=64,\n",
    "    verbose=2,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tb_callback, es_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = model.evaluate(x=x_test, y=y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 186.110, RMSE: 13.642, MAE: 9.058\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: %.3f, RMSE: %.3f, MAE: %.3f\" % (mse, np.sqrt(mse), mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bung\n",
    "Welche Vernderungen knnten fr starkes Overfitting sorgen? (Das lsst sich theoretisch wie praktisch beantworten.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ads3-04-tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1a6e6f29cbcbfbec7ea07bf2caf22536ab5261d24fd5afc19f63e3ce92e1134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
